{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method\n",
    "\n",
    "Pengambilan keputusan yang dilakukan oleh manusia dalam kehidupan sehari-hari seringkali dipengaruhi oleh pendapat dari orang lain ataupun pendapat orang banyak. Seperti misalnya dalam pemilihan untuk menentukan pembelian Handphone berdasarkan pertimbangan review-review dari produk. Contoh lain pemilihan menentukan buku yang ingin dibeli, bisa saja suatu topik yang sama terdapat beberapa buku yang memiliki judul yang berbeda ataupun pengarang yang berbeda, sehingga dalam pemilihan buku mana yang akan dibeli manusia sering mempertimbangkan review-review dari buku-buku tersebut. Seringkali, pengambilan keputusan oleh sekelompok individu menghasilkan hasil yang lebih baik daripada keputusan yang dibuat oleh salah individu saja.\n",
    "\n",
    "## Pengertian Ensemble Method\n",
    "\n",
    "Machine Learning sering kali melibatkan penyesuaian dan juga evaluasi dari suatu model pada dataset. Penyesuaian dan evaluasi ini bertujuan untuk mencari model mana yang paling tepat / memiliki performa yang baik pada dataset. Mengingat bahwa kita tidak dapat mengetahui model mana yang akan memiliki performa yang terbaik pada dataset, biasanya pencarian model terbaik akan dilakukan dengan cara melibatkan banyak trial and error sampai ditemukan model yang memiliki performa terbaik untuk dataset. Penggunaan trial dan error untuk menemukan model terbaik tentunya akan membutuhkan waktu relatif lama. Metode ensemble mengatasi masalah ini, dimana metode ensemble dengan cara menyiapkan beberapa model yang berbeda kemudian menggambungkan prediksi dari model-model tersebut.\n",
    "\n",
    "Beberapa pengertian ensemble method\n",
    "\n",
    "- Ensemble method merupakan kombinasi model yang memiliki performa  lebih baik jika dibandingkan masing-masing model penyusunnya.\n",
    "- Ensemble method merupakan salah satu Teknik machine learning yang menggabungkan beberapa model untuk menghasilkan satu model prediksi yang optimal.\n",
    "- Ensemble method merupakan Teknik yang membuat beberapa model dan kemudian menggabungkannya untuk menghasilkan hasil yang lebih baik, biasanya menghasilkan solusi yang lebih akurat daripada satu model saja.\n",
    "- Ensemble method merupakan Suatu teknik untuk menggabungkan prediksi beberapa model dasar yang dibangun dengan algoritma pembelajaran yang diberikan untuk meningkatkan kemampuan generalisasi / kehandalan dibandingkan satu model saja.\n",
    "- Ensemble method disebut sebagai Seni menggabungkan beragam kelompok algoritma (model individu) secara bersama-sama untuk berimprovisasi pada stabilitas dan kekuatan prediksi model.\n",
    "\n",
    "Ilustrasi dari ensemble method dapat dilihat pada gambar. Pada ilustrasi tersebut adalah contoh contoh teknik yang paling sederhana. Misalnya, jika ensemble method diterapkan pada masalah klasifikasi maka dapat dipilih beberapa algoritma klasifikasi untuk melakukan pelatihan dan prediksi pada suatu dataset. Algoritma yang dapat digunakan seperti Logistic Regression classifier, SVM classifiers, KNN, decision tree, dan lain-lain. Setiap algoritma akan mengasilkan prediksinya masing-masing dan prediksi akhir dari ensemble method untuk permasalahan klasifikasi adalah dengan cara memilih hasil prediksi yang paling sering muncul / mayoritas. Pada gambar 8.1 hasil prediksi dari tiga buah algoritma adalah kelas 1 sehingga hasil akhir prediksi adalah kelas 1 untuk data training yang baru.\n",
    "\n",
    "![Ilustrasi Ensemble Method](assets/voting-ensemble-method-640x349.png \"Ilustrasi Ensemble Method\")\n",
    "\n",
    "## Kategori Ensemble Method\n",
    "\n",
    "Ensemble method dikategorikan kedalam dua buah kelompok yaitu metode ensemble homogen dan metode ensemble heterogen.\n",
    "\n",
    "### Ensemble Method Homogen\n",
    "\n",
    "Homogen dalam ensemble method berarti model klafisifkasi atau model regresi yang dibangun menggunakan algoritma yang sama hanya saja dataset yang digunakan adalah resampling dari dataset awal. Sehingga mungkin saja algoritma yang sama diterapkan terhadap sub-dataset yang berbeda-beda. Jenis metode ansambel ini biasanya digunakan untuk sejumlah besar kumpulan data. Metode yang termasuk kedalam metode ensemble homogen adalah ***bagging*** dan ***boosting***.\n",
    "\n",
    "### Ensemble Method Hetegoren\n",
    "\n",
    "Metode ansambel heterogen itu adalah kombinasi dari berbagai jenis algoritma klasifikasi dimana algoritma-algoritma yang berbeda diterapkan terhadap data yang sama. Metode yang termasuk kedalam metode ensemble heterogen adalah ***stacking***.\n",
    "\n",
    "## Boostrap\n",
    "\n",
    "Bootstrap merupakan salah satu metode statistika yang dapat digunakan untuk melakukan resampling data. Proses pembuatan satu sampel data adalah sebagai berikut:\n",
    "\n",
    "1. Pilih ukuran sampel\n",
    "2.\tKetika ukuran dari sampel saat ini lebih kecil dari ukuran yang dipilih\n",
    "    * Pilih observasi secara acak dari dataset\n",
    "    * Tambahkan kedalam sample\n",
    "    * Ulangi Langkah a sampai ukuran sample sesuai ukuran yang dipilih\n",
    "\n",
    "Bootsrap dapat juga digunakan untuk estimasi performa dari machine learning yaitu dengan Teknik boostrap didapatkan data training dan juga data testing. Sampel ini tidak termasuk dalam sampel tertentu disebut sampel out-of-bag, atau disingkat OOB. OOB inilah yang nantinya akan menjadi data testing. Langkah-langkah yang dapat digunakan adalah sebagai berikut,\n",
    "\n",
    "1. Pilih sejumlah sampel bootstrap yang akan dilakukan\n",
    "2. Pilih ukuran sampel\n",
    "    * Pilih observasi secara acak dari dataset\n",
    "    * Tambahkan kedalam sample\n",
    "    * Ulangi Langkah a sampai ukuran sample sesuai ukuran yang dipilih\n",
    "3.\tUntuk setiap sampel bootsrap lakukan :\n",
    "    * Gambarlah sampel dengan pengganti dengan ukuran yang dipilih\n",
    "    * Lakukan pelatihan pada sampel data\n",
    "    * Estimasi performa dari model menggunakan out-of-bag data\n",
    "4.\tHitung rata-rata prediksi setiap sample sebagai estimasi performa akhir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jenis-jenis Ensemble Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging - Homogen\n",
    "#### Bagging \n",
    "\n",
    "Bagging merupakan singkatan dari bootstrap aggregating. Bagging dapat digunakan dalam permasalah klasifikasi dan regresi. Ketika digunakan untuk permasalahan regresi maka hasil prediksi dari bagging adalah rata-rata dari prediksi dari setiap model. Sedangkan jika digunakan untuk permasalahan klasifikasi hasil  prediksi dari bagging adalah kelas mayoritas. Bagging merupakan prosedur umum yang dapat digunakan untuk mengurangi varians untuk algoritma yang memiliki varians tinggi. Gambar dibawah ini merupakan ilustrasi dari Bagging.\n",
    "\n",
    "![Ilustrasi Bagging](assets/bagging_illustration.png 'Ilustrasi Bagging')\n",
    "\n",
    "Contoh algoritma yang memiliki variance yang tinggi adalah Classification and Regression Tree (CART). CART sangat sensitive terhadap data pelatihan yang spesifik.  Jika data pelatihan diubah (misalnya, CART dilatih pada subset data training), CART yang dihasilkan bisa sangat berbeda sehingga dapat menghasilkan prediksi yang sangat berbeda. Asumsikan terdapat dataset yang memiliki 1000 baris data(x) dan akan digunakan algoritma CART. Maka tahapan Bagging dengan menggunakan algoritma CART adalah sebagai berikut,\n",
    "\n",
    "1.\tBuat resample data / sub-data dengan acak dari dataset. Missal dibuat masing-masing sub-data memiliki 100 baris data. Salah satu tenik resampling data yang dapat digunakan adalah Metode Boostrap. \n",
    "2.\tLakukan pelatihan menggunakan CART untuk setiap sub-set data\n",
    "3.\tDengan adanya sub-data baru, maka akan didapatkan hasil prediksi dari masing-masing data. Untuk persamalan klasifikasi hasil prediksi akhir didapat dari mayoritas kelas yang muncul, sedangkan untuk permasalan regersi hasil prediksi didapat dengan cara menghitung prediksi rata-rata dari setiap model.\n",
    "\n",
    "#### Random Forest\n",
    "\n",
    "Random forest merupakan algoritma yang dikembangkan oleh Leo Breiman dan Adele Cutler. Random Forests merupakan perbaikan dari metode bagging yang menggunakan algoritma decision tree. Pada metode bagging, decision tree yang dibuat dapat memiliki banyak kesamaan struktur dan sehingg dapat menghasilkan korelasi yang tinggi. Sedangkan dengan menggambungkan hasil prediksi dari beberapa model dalam ensemble method akan lebih handal ketika melakukan prediksi terhadap sub-model yang tidak berkorelasi atau korelasinya rendah. Random forest mengubah algoritma pembelajaran pada sub-tree sehingga prediksi yang dihasilkan oleh semua sub-tree dapat memiliki korelasi yang kecil.\n",
    "\n",
    "Dalam decision tree saat memilih split poin maka algoritma pembelajaran di izinkan untuk mempertimbangkan seluruh fitur/ variable x untuk memilih split-poin paling optimal. Random forest merubah prosedur ini sehingga pada random forest  penentuan split-poin tidak dilkukan terhadap keseluruhan fitur akan tetapi algoritma pembelajaran dibatasi pada beberapa fitur yang dipilih secara acak. Jumlah fitur yang dapat dicari untuk setiap split-point(m) harus ditentukan dan menjadi parameter dari algoritma. Dapat dilakukan ujicoba dengan nilai yang berbeda-beda dan disesuaikan dengan menggunakan cross validation. Gambar dibawah ini merupakan ilustrasi dari random forest.\n",
    "\n",
    "![Ilustrasi Random Forest](assets/random_forest_illustration.png 'Ilustrasi Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting - Homogen\n",
    "\n",
    "#### Boosting\n",
    "\n",
    "Teknik Boosting dirumuskan oleh Yoav Freund dan Robert Schapire pada tahun 1995. Boosting merupakan salah satu metode ensemble yang dapat digunakan untuk mengurangi bias pada algoritma pembelajaran. Boosting dapat digunakan untuk permasalahan klasifikasi maupun permasalahan regresi. Teknik boosting menggunakan pemrosesan secara sequential dimana keluaran dari proses sembelumnya akan menjadi masukan dari untuk proses selanjutnya.\n",
    "\n",
    "Boosting menciptakan “strong Classifier” dari sejumlah “weak classifier”. Hal ini dilakukan dengan cara membangun model dari data training, kemudian membuat model kedua yang mencoba untuk memperbaiki error dari model pertama. Kemudian Model akan terus ditambahkan hingga data training dapat diprediksi dengan sempurna atau dibatasi berdasarkan jumlah model maksimum yang ditambahkan. Gambar dibawah ini merupakan ilustrasi dari boosting.\n",
    "\n",
    "![Ilustrasi Boosting](assets/boosting-ensemble-method.png 'Ilustrasi Boosting')\n",
    "\n",
    "#### AdaBoost\n",
    "\n",
    "Adaboost merupakan singkatan dari Adaptive Boosting. AdaBoost adalah algoritma boosting pertama yang sukses dikembangkan untuk binary classification. AdaBoost dapat digunakan untuk meningkatkan kinerja algoritma pembelajaran mesin apa pun. Ini paling baik digunakan dengan “weak-learner”. Algoritma yang paling cocok dan paling umum digunakan dengan AdaBoost adalah decision tree dengan satu level. Yaitu tree yang hanya memiliki 1 rood node dan node yang lainnya adalah leafnode. Tree ini sering disebut dengan istilah ***decision stumps***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking - Heterogen\n",
    "\n",
    "Stacking berbeda dengan boosting dan bagging. Stacking dapat menggunakan algoritma yang berbeda-beda pada data yang sama. Dalam proses pelatihan stacking belajar untuk menggabungkan model dasar menggunakan meta-model. Dapat disimpulkan bahwa ide dasar dari stacking adalah mempelajari beberapa weak-learner yang berbeda dan menggabungkannya dengan melatih meta-mode untuk menghasilkan prediksi berdasarkan beberapa prediksi yang dikembalikan oleh meta-model. Jadi, dua hal yang perlu didefinisikan untuk membangun model adalah: L weak-learner yang akan dilatih dan meta-model yang menggabungkannya.\n",
    "\n",
    "Sebagai contoh dalam permasalahan klasifikasi dapat dipilih wak-learner (L) adalah KNN classifier,  logistic regression, dan SVM. Dan kemudian dipilih 1 model sebagai meta-model, misal ANN. Sehingga keluaran dari 3 buah weak-learner akan menjadi masukan dari ANN dan akan menghasilkan 1buah keputusan final.\n",
    "Tahapan Stacking :\n",
    "1.\tPisahkan data pelatihan menjadi dua bagian sebagai bagian1 dan bagian2. Dapat juga menggunakan Teknik k-fold cross-validation.\n",
    "2.\tPilih L weak-learner (missal KNN classifier,  logistic regression, dan SVM) dan lakukan pelatihan terhadap data bagian1 dengan masing-masing algoritma.\n",
    "3.\tUntuk setiap L weak-learner lakukan prediksi mengunakan data bagian2.\n",
    "4.\tLakukan pelatihan pada data bagian2 dengan meta-model dengan menggunakan hasil prediksi yang dibuat oleh L weak-learner sebagai input.\n",
    "\n",
    "#### Voting\n",
    "\n",
    "Metode voting adalah jenis metode ensemble yang menggabungkan prediksi beberapa model dengan Voting. Metode voting  dapat digunakan untuk membuat prediksi yang lebih akurat daripada model tunggal mana pun dengan menggabungkan pengetahuan dan keahlian beberapa pakar. Idenya adalah, dengan menggabungkan prediksi beberapa model, Anda dapat mengurangi varians dan menghindari overfitting. Metode voting  biasanya digunakan ketika ada beberapa model dengan konfigurasi yang berbeda, atau ketika ada beberapa ahli dengan pendapat yang berbeda. Dalam kedua kasus tersebut, metode voting dapat membantu menghasilkan prediksi yang lebih akurat dengan menggabungkan informasi dari berbagai sumber. Gambar di bawah ini merupakan metode voting.\n",
    "\n",
    "![Ilustrasi Voting](assets/Voting-ensemble-method-2.png 'Ilustrasi Voting')\n",
    "\n",
    "Terdapat 2 pendekatan dalam voting untuk menentukan mayoritas nilai voting, yaitu ***hard voting*** dan ***soft voting***. \n",
    "\n",
    "- Hard voting menggunakan prediksi kelas terbanyak sebagai hasil akhir\n",
    "- Soft voting menggunakan probabilitas kelas sebagai hasil akhir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
